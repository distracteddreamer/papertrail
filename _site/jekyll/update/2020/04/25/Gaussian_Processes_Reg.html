<!DOCTYPE html>
<html lang="en"><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
      <title>Paper Trail</title>
      <meta name="generator" content="Jekyll v3.8.5" />
      <meta property="og:title" content="Your awesome title" />
      <meta property="og:locale" content="en_US" />
      <meta name="description" content="Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description." />
      <meta property="og:description" content="Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description." />
      <link rel="canonical" href="http://localhost:4000/papertrail/" />
      <meta property="og:url" content="http://localhost:4000/papertrail/" />
      <meta property="og:site_name" content="Your awesome title" />
      <script type="application/ld+json">
      {"name":"Your awesome title","description":"Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.","@type":"WebSite","url":"http://localhost:4000/papertrail/","headline":"Your awesome title","@context":"https://schema.org"}</script>
    
      <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          jax: ["input/TeX", "output/HTML-CSS"],
          tex2jax: {
            inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
            displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
            processEscapes: true,
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
          }
          //,
          //displayAlign: "left",
          //displayIndent: "2em"
        });
      </script>
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


      <!-- End Jekyll SEO tag -->
      <link rel="stylesheet" href="/papertrail/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/papertrail/feed.xml" title="Your awesome title" /></head>

<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/papertrail/">Your awesome title</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/papertrail/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Gaussian Processes for Regression</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2020-04-25T21:08:07+01:00" itemprop="datePublished">Apr 25, 2020
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In this notebook I am recreating the simple Gaussian Process example described in <a href="http://www.robots.ox.ac.uk/~mebden/reports/GPtutorial_old.pdf">this</a> tutorial. The results are not identical since the tutorial provides the values only for the inputs $\mathbf{x}$ and not for the outputs $\mathbf{y}$ for which I read off approximate values from the plot in Figure 1 of the tutorial.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>We have the following $n = 6$ observations</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">.75</span><span class="p">,</span> <span class="o">-</span><span class="mf">.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">.25</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">1.62</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.09</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.82</span><span class="p">])</span>
<span class="n">noise</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">'ok'</span><span class="p">,</span> <span class="n">ecolor</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">elinewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">3</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'6 noisy observations'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">);</span>
</code></pre></div></div>

<p><img src="/papertrail/assets/Gaussian_Processes_Reg/output_4_0.png" alt="png" /></p>

<p>We assume that these observations come from an $n$-dimensional normal distribution as follows:</p>

<ul>
  <li>There is an underlying function $\mathbf{f}(x) \sim \mathcal{N}(\mathbf{0}, K)$</li>
  <li>The observations $\mathbf{y}$ have additional noise associated with them such that</li>
</ul>

<script type="math/tex; mode=display">\mathbf{y} = \mathbf{f}(x) + \epsilon\\
\epsilon  \sim \mathcal{N}(\mathbf{0}, K)\\
\mathbf{y} \sim \mathcal{N}(\mathbf{0}, K + \sigma_n^2)</script>

<p>The important part is the covariance matrix $K$ which is derived from the data and where each element $K_{vw}$ is defined via a <strong>kernel</strong> function $k(x_v, x_w)$. The function $k$ is based on our knowledge about the data distribution. Here we will use the squared exponential:</p>

<script type="math/tex; mode=display">k(x, x') = \sigma_f^2\exp\left[\frac{-(x - x')^2}{2l^2}\right]</script>

<p>where $\sigma_f$ and $l$ are hyperparameters which we collectively denote $\theta$. Sometimes we might have prior knowledge about these. Actually $\sigma_n$ is also a hyperparameter but here we have been given a value for it of $\sigma_n = 0.3$. In the absence of such knowledge, we can estimate it e.g. via MAP estimate i.e.</p>

<script type="math/tex; mode=display">\theta = \arg\max_{\theta} p(\theta \vert \mathbf{x}, \mathbf{y})\\
= \arg\max_{\theta} \frac{p(\mathbf{y} \vert \theta, \mathbf{x}) p(\theta \vert \mathbf{x})}{p(\mathbf{y} \vert \mathbf{x})}</script>

<p>If we don’t have any prior knowledge about how $\theta$ should be, implying that $p(\theta \vert \mathbf{x})$ is uniform thus $p(\theta \vert \mathbf{x}) = \text{constant}$. Then since $p(\mathbf{y} \vert \mathbf{x})$ doesn’t depend on $\theta$ we get</p>

<script type="math/tex; mode=display">\theta = \arg\max_{\theta} p(\mathbf{y} \vert \theta, \mathbf{x}) = \arg\max_{\theta} \log p(\mathbf{y} \vert \theta, \mathbf{x})</script>

<p>Although we didn’t explicitly specify the dependence on $\theta$ above, actually $p(\mathbf{y} \vert \theta, \mathbf{x}) = \mathcal{N}(\mathbf{0}, K + \sigma_n^2)$ which means</p>

<script type="math/tex; mode=display">\log p(\mathbf{y} \vert \theta, \mathbf{x}) = 
-\frac{1}{2}\left(\log\left\lvert K + \sigma_n^2 \right\rvert  + \mathbf{y}^T\left(K + \sigma_n^2\right)^{-1}\mathbf{y}\right) + A</script>

<p>where $A$ comprises terms that don’t depend on $\theta$. Thus</p>

<script type="math/tex; mode=display">\theta = \arg\max_{\theta}\left(-\log\left\lvert K + \sigma_n^2 \right\rvert  - \mathbf{y}^T\left(K + \sigma_n^2\right)^{-1}\mathbf{y}\right) = \arg\min_{\theta}\left(\log\left\lvert K + \sigma_n^2 \right\rvert  + \mathbf{y}^T\left(K + \sigma_n^2\right)^{-1}\mathbf{y}\right)</script>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sq_exp_kernel</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x2</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="n">x1</span>
    <span class="n">l_sq</span><span class="p">,</span> <span class="n">sigma_f_sq</span> <span class="o">=</span> <span class="n">theta</span>
    <span class="n">sq_diff</span> <span class="o">=</span> <span class="p">(</span><span class="n">x1</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">-</span> <span class="n">x2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="n">exp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">sq_diff</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">l_sq</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">sigma_f_sq</span><span class="p">)</span> <span class="o">*</span> <span class="n">exp</span>

<span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">var_n</span><span class="p">):</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">sq_exp_kernel</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">K_noise</span> <span class="o">=</span> <span class="n">K</span> <span class="o">+</span> <span class="n">var_n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">K_noise</span><span class="p">))</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="o">@</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">K_noise</span><span class="p">))</span><span class="o">@</span><span class="n">y</span>  
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t0</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">t0</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s">'Nelder-Mead'</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span>
<span class="n">l</span><span class="p">,</span> <span class="n">sigma_f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
<span class="n">l</span><span class="p">,</span> <span class="n">sigma_f</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0.9973985356503553, 1.2696785734036715)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">sq_exp_kernel</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">6</span><span class="p">))</span><span class="o">.</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[1.7 , 1.42, 1.22, 0.88, 0.74, 0.52],
       [1.42, 1.7 , 1.56, 1.35, 1.22, 0.98],
       [1.22, 1.56, 1.7 , 1.52, 1.42, 1.22],
       [0.88, 1.35, 1.52, 1.7 , 1.59, 1.49],
       [0.74, 1.22, 1.42, 1.59, 1.7 , 1.56],
       [0.52, 0.98, 1.22, 1.49, 1.56, 1.7 ]])
</code></pre></div></div>

<p>Suppose $m$ new input datapoints $\mathbf{x}^*$ are introduced, then we get a $(n + m)$ dimensional normal distribution whose noise variance is the same but whose other covariance matrix becomes:</p>

<script type="math/tex; mode=display">% <![CDATA[
K' = \begin{bmatrix}
K & K^{*T}\\
K^* & K^{**}
\end{bmatrix} \\
K^*_{uv} = k(x_u, x_v),\text{ }x_u \in \mathbf{x}, x_v \in \mathbf{x}^* \\
K^{**}_{uv} = k(x_u, x_v),\text{ }x_u, x_v \in \mathbf{x}^* %]]></script>

<p>where we abuse the element of $\in$ notation a bit to indicate that an element belongs to a vector. Basically constructing the matrix in this manner lets us reuse the previously computed $K$ instead of computing it again.</p>

<p>Although we can write down the joint distribution for $\mathbf{y}$ and $\mathbf{y^*}$ as follows</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{bmatrix}
\mathbf{y}\\
\mathbf{y}^*
\end{bmatrix}  = 
\begin{bmatrix}
K & K^{*T}\\
K^* & K^{**}
\end{bmatrix} %]]></script>

<p>we are actually interested in the conditional distribution. Letting $S’ = K’ + \sigma_nI$, with the $S, S^{*}, S^{<strong>}$ the blocks of $S’$ corresponding to $K, K^{*}, K^{</strong>}$:</p>

<script type="math/tex; mode=display">p(\mathbf{y}^* | \mathbf{y}) = \mathcal{N}\left(S^*S^{-1}\mathbf{y}, S^{**} - S^{*}S^{-1}S^{*T}\right)</script>

<p>because using our data we would like to predict the output for a given input.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">])</span>
<span class="n">K_star</span> <span class="o">=</span> <span class="n">sq_exp_kernel</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">x_star</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">K_star_star</span> <span class="o">=</span> <span class="n">sq_exp_kernel</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">x_star</span><span class="p">)</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">sq_exp_kernel</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="n">K_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
    <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">K</span><span class="p">,</span> <span class="n">K_star</span><span class="o">.</span><span class="n">T</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
     <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">K_star</span><span class="p">,</span> <span class="n">K_star_star</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)]</span>
<span class="p">)</span>

<span class="n">S_p</span> <span class="o">=</span> <span class="n">K_p</span> <span class="o">+</span> <span class="p">(</span><span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">K_p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">S</span> <span class="o">=</span> <span class="n">S_p</span><span class="p">[:</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">S_star</span> <span class="o">=</span> <span class="n">S_p</span><span class="p">[</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="p">:</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">S_star_star</span> <span class="o">=</span> <span class="n">S_p</span><span class="p">[</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:]</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">S_star</span><span class="p">,</span> <span class="n">S_p</span><span class="p">[:</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">K_p</span><span class="o">.</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[1.61, 1.42, 1.22, 0.88, 0.74, 0.52, 0.38],
       [1.42, 1.61, 1.56, 1.35, 1.22, 0.98, 0.78],
       [1.22, 1.56, 1.61, 1.52, 1.42, 1.22, 1.02],
       [0.88, 1.35, 1.52, 1.61, 1.59, 1.49, 1.35],
       [0.74, 1.22, 1.42, 1.59, 1.61, 1.56, 1.46],
       [0.52, 0.98, 1.22, 1.49, 1.56, 1.61, 1.58],
       [0.38, 0.78, 1.02, 1.35, 1.46, 1.58, 1.61]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">S_p</span><span class="o">.</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[1.7 , 1.42, 1.22, 0.88, 0.74, 0.52, 0.38],
       [1.42, 1.7 , 1.56, 1.35, 1.22, 0.98, 0.78],
       [1.22, 1.56, 1.7 , 1.52, 1.42, 1.22, 1.02],
       [0.88, 1.35, 1.52, 1.7 , 1.59, 1.49, 1.35],
       [0.74, 1.22, 1.42, 1.59, 1.7 , 1.56, 1.46],
       [0.52, 0.98, 1.22, 1.49, 1.56, 1.7 , 1.58],
       [0.38, 0.78, 1.02, 1.35, 1.46, 1.58, 1.7 ]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">W</span> <span class="o">=</span> <span class="p">(</span><span class="n">S_star</span><span class="o">@</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">S</span><span class="p">))</span>
<span class="n">y_star_hat</span> <span class="o">=</span> <span class="n">W</span><span class="o">@</span><span class="n">y</span>
<span class="n">y_star_var</span> <span class="o">=</span> <span class="n">S_star_star</span> <span class="o">-</span> <span class="n">W</span><span class="o">@</span><span class="n">S_star</span><span class="o">.</span><span class="n">T</span>
<span class="n">y_star_hat</span><span class="p">,</span> <span class="n">y_star_var</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array([0.92699289]), array([[0.20631961]]))
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">x_star</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="n">K_star</span> <span class="o">=</span> <span class="n">sq_exp_kernel</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x_star</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">K_star_star</span> <span class="o">=</span> <span class="n">sq_exp_kernel</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x_star</span><span class="p">)</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">sq_exp_kernel</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

    <span class="n">K_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
        <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">K</span><span class="p">,</span> <span class="n">K_star</span><span class="o">.</span><span class="n">T</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
         <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">K_star</span><span class="p">,</span> <span class="n">K_star_star</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)]</span>
    <span class="p">)</span>

    <span class="n">S_p</span> <span class="o">=</span> <span class="n">K_p</span> <span class="o">+</span> <span class="p">(</span><span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">K_p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">S</span> <span class="o">=</span> <span class="n">S_p</span><span class="p">[:</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">S_star</span> <span class="o">=</span> <span class="n">S_p</span><span class="p">[</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="p">:</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">S_star_star</span> <span class="o">=</span> <span class="n">S_p</span><span class="p">[</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:]</span>
    
    <span class="n">W</span> <span class="o">=</span> <span class="p">(</span><span class="n">S_star</span><span class="o">@</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">S</span><span class="p">))</span>
    <span class="n">y_star_hat</span> <span class="o">=</span> <span class="n">W</span><span class="o">@</span><span class="n">y</span>
    <span class="n">y_star_var</span> <span class="o">=</span> <span class="n">S_star_star</span> <span class="o">-</span> <span class="n">W</span><span class="o">@</span><span class="n">S_star</span><span class="o">.</span><span class="n">T</span>
    
    <span class="k">return</span> <span class="n">y_star_hat</span><span class="p">,</span> <span class="n">y_star_var</span>
</code></pre></div></div>

<p>Now we will repeat the above for 1000 different points. First we will just input each point individually and get a prediction.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">1.6</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,))))</span>
<span class="n">pred_mean</span><span class="p">,</span> <span class="n">pred_var</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">p</span><span class="p">]),</span> <span class="n">noise</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> 
                           <span class="n">points</span><span class="p">])</span>
<span class="n">pred_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">pred_mean</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="n">pred_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">pred_var</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="n">interval</span> <span class="o">=</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">pred_var</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Use 95% confidence interval
</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">'ko'</span><span class="p">,</span> <span class="n">ecolor</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">elinewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">3</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">x_star</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y_star_hat</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_star_var</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">fmt</span><span class="o">=</span><span class="s">'bo'</span><span class="p">,</span> <span class="n">ecolor</span><span class="o">=</span><span class="s">'lightgreen'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">pred_mean</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">pred_mean</span> <span class="o">-</span> <span class="n">interval</span><span class="p">,</span> <span class="n">pred_mean</span> <span class="o">+</span> <span class="n">interval</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'6 noisy observations along with new points with pointwise 95</span><span class="si">% </span><span class="s">confidence intervals'</span><span class="p">,</span>
         <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">);</span>

</code></pre></div></div>

<p><img src="/papertrail/assets/Gaussian_Processes_Reg/output_21_0.png" alt="png" /></p>

<p>Now let us predict in one go.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred_mean_all</span><span class="p">,</span> <span class="n">pred_var_all</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div>

<p>This time we can’t use confidence intervals we have multivariate conditional where the covariance matrix is not diagonal as we can see below</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">pred_var_all</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'hot'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">pred_var_all</span><span class="o">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">vmax</span><span class="o">=</span><span class="n">pred_var_all</span><span class="o">.</span><span class="nb">max</span><span class="p">());</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">);</span>
</code></pre></div></div>

<p><img src="/papertrail/assets/Gaussian_Processes_Reg/output_25_0.png" alt="png" /></p>

<p>Instead we will sample a number of 1000-d vectors and plot those</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">pred_mean_all</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">pred_var_all</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,))</span>
</code></pre></div></div>

<p>As we can see in the plot above, the diagonal predominates over other values and below we notice that the shape of the plots of the samples roughly follows the envelope of the confidence intervals.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">samples</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'lightcoral'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">points</span><span class="p">[::</span><span class="mi">10</span><span class="p">],</span> <span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">][::</span><span class="mi">10</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s">'b'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s">'ko'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'6 noisy observations along with samples for new points'</span><span class="p">,</span>
         <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">);</span>
</code></pre></div></div>

<p><img src="/papertrail/assets/Gaussian_Processes_Reg/output_29_0.png" alt="png" /></p>


  </div><a class="u-url" href="/papertrail/jekyll/update/2020/04/25/Gaussian_Processes_Reg.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/papertrail/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Your awesome title</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Your awesome title</li><li><a class="u-email" href="mailto:your-email@example.com">your-email@example.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jekyll"><svg class="svg-icon"><use xlink:href="/papertrail/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jekyll</span></a></li><li><a href="https://www.twitter.com/jekyllrb"><svg class="svg-icon"><use xlink:href="/papertrail/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jekyllrb</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
