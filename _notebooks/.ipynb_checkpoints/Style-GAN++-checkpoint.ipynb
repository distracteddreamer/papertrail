{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The revised style block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleBlock(tf.keras.models.Model):\n",
    "    def __init__(self, conv_kwargs, dense_kwargs):\n",
    "        self.conv = tf.keras.layers.Conv2D(**conv_kwargs)\n",
    "        self.bias = self.add_weight(shape=(conv_kwargs['filters'],),\n",
    "                             initializer='zeros',\n",
    "                             trainable=True)\n",
    "        self.dense_mod = tf.keras.layers.Dense(**dense_kwargs)\n",
    "        \n",
    "    def __call__(self, x, style, noise):\n",
    "        y = self.dense_mod(style)\n",
    "        x = self.conv(x) * y\n",
    "        x = x / tf.math.reduce_std(x, axis=[1, 2])\n",
    "        x = tf.nn.bias_add(x, self.bias)\n",
    "        x = x + noise\n",
    "        # TODO: confirm these are the axis\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let there be $C$ filters in the input and $F$ filters in the output. Let the kernel for the $f$-th filter $w_f$ have shape $H \\times W$ and let $p$ be a $C \\times H \\times W$ size patch of the input. The pixel in the $f$-th channel of the output $a_{fi'j'}$ resulting from this input patch convolved with the $f$-th kernel is given as \n",
    "\n",
    "$$a_{fi'j'} = \\sum_{c=0}^{C-1}\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}w_{fcij}p_{cij}$$\n",
    "    \n",
    "In the modulation step we scale the output feature maps of the conv layer by a $F$-dimensional style vector $y$. But we could equivalently achieve this result by scaling the conv kernel so that instead of $a'_{fi'j'} = y_fa_{fi'j'}$ we have \n",
    "\n",
    "$$\n",
    "w'_f = y_fw_f \\\\\n",
    "a'_{fi'j'} = \\sum_{c=0}^{C-1}\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}w'_{fcij}p_{cij} \\\\\n",
    "$$\n",
    "\n",
    "If $p_{cij} \\sim \\mathcal{N}(\\mu, 1)$ (i.i.d with std of 1), then std of the $f$-channel activations is\n",
    "\n",
    "$$\\text{Var}(a_f) = \\text{Var}\\left(\\sum_{cij}w_{fcij}p_{cij}\\right)\n",
    "= \\sum_{cij}\\text{Var}(w_{fcij}p_{cij})\n",
    "= \\sum_{cij}w_{fcij}^2\\text{Var}(p_{cij})\n",
    "= \\sum_{cij}w_{fcij}^2\n",
    "\\\\\\sigma_f = \\sqrt{\\text{Var}(a_f)} = \\sqrt{\\sum_{cij}w_{fcij}^2}$$\n",
    "\n",
    "Since in the norm step the feature maps are scaled by their std, if $p_{cij} \\sim \\mathcal{N}(\\mu, 1)$, then the outputs are scaled by the $L_2$ norm of the weights.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly the variance scaling can be incorporated into the kernel\n",
    "\n",
    "$$\n",
    "w''_f = w'_f / ||w'_f||_2\\\\\n",
    "a''_{fi'j'} = \\sum_{c=0}^{C-1}\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}w''_{fcij}p_{cij} \\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers.convolutional import Conv\n",
    "from tensorflow.python import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleConv(Conv):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.eps = kwargs.pop('eps')\n",
    "        super(StyleConv, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def _mod_demod_kernel(self, style, noise):\n",
    "        kernel =  self.kernel * style\n",
    "        l2_norm = tf.norm(tf.reshape(kernel, [-1, tf.shape(kernel)[-1]]),\n",
    "                          axis=0, ord=2, keepdims=True)\n",
    "        kernel = kernel / (l2_norm + self.eps)\n",
    "        return kernel\n",
    "    \n",
    "    def call(self, x, style, noise):\n",
    "        outputs = self._convolution_op(x, self._mod_demod_kernel(style))\n",
    "        outputs = outputs + noise\n",
    "        if self.use_bias:\n",
    "          if self.data_format == 'channels_first':\n",
    "            if self.rank == 1:\n",
    "              # nn.bias_add does not accept a 1D input tensor.\n",
    "              bias = array_ops.reshape(self.bias, (1, self.filters, 1))\n",
    "              outputs += bias\n",
    "            else:\n",
    "              outputs = nn.bias_add(outputs, self.bias, data_format='NCHW')\n",
    "          else:\n",
    "            outputs = nn.bias_add(outputs, self.bias, data_format='NHWC')\n",
    "        \n",
    "        if self.activation is not None:\n",
    "          return self.activation(outputs)\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "class StyleConv2D(StyleConv):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs['rank'] = 2\n",
    "        super(StyleConv2D, self).__init__(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "\n",
    "- Dimensionality of $Z$ and $W$: 512\n",
    "- Mapping network architecture \n",
    "    - 8 fully connected layers\n",
    "    - 100$\\times$ lower lr\n",
    "- Architecture\n",
    "    - leaky ReLU, $\\alpha=0.2$\n",
    "    - bilinear filtering in all up/downsampling layers (?)\n",
    "    - minibatch std layer at end of discriminator\n",
    "- Training\n",
    "    - equalized lr for all trainable params (?)\n",
    "    - EMA of generator weights\n",
    "    - style mixing reg\n",
    "    - non-saturating logistic loss with $R_1$ reg\n",
    "    - Adam optimiser ($\\beta_1 = 0, \\beta_2 = 0.99, \\epsilon = 10^{-8}$)\n",
    "    - batch_size 32\n",
    "    - 8 GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
