{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies\n",
    "- Batch renorm\n",
    "- LayerNorm\n",
    "- InstanceNorm\n",
    "- GroupNorm\n",
    "- ResnetV2-50\n",
    "- InceptionV3\n",
    "- Augmentation from 26\n",
    "- VGG-A\n",
    "- PReLU\n",
    "- Maxout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FRN(tf.keras.models.Model):\n",
    "    # TODO: write init\n",
    "    \n",
    "    def __init__(self, eps=None, eps_mode='abs'):\n",
    "        super(FRN, self).__init__()\n",
    "        if self.eps is not None:\n",
    "            self.eps = eps\n",
    "        else:\n",
    "            self.eps = self.add_weight(\"eps\", shape=[])\n",
    "        self.dense = tf.keras.layers.Dense(units=1)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        x: feature_maps of shape (B, H, W, F)\n",
    "        \"\"\"\n",
    "        # (B, 1, 1, F)\n",
    "        # If H = W = 1, then mean_sq_norm = x**2\n",
    "        mean_sq_norm = tf.reduce_mean(x ** 2, axis=[1, 2], keepdims=True)\n",
    "        # If H = W = 1, then x_hat = x / (+sqrt(x**2 + eps)) ~ x / |x| ~ sign(x)\n",
    "        x_hat = x / tf.sqrt(mean_sq_norm**2 + self.eps)\n",
    "        x_hat = tf.reshape(x_hat, [-1, 1])\n",
    "        y = self.dense(x_hat)\n",
    "        y = tf.reshape(y, tf.shape(x))\n",
    "        return y\n",
    "    \n",
    "    \n",
    "class TLU(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(TLU, self).__init__()\n",
    "        self.tau = self.add_weight(\"tau\", shape=[])\n",
    "    def call(self, x):\n",
    "        return tf.maximum(x, self.tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradients of TLU\n",
    "    - $y = \\max(x, \\tau) = x\\{x \\gt \\tau\\} + \\tau\\{x \\leq \\tau\\}$\n",
    "    - $dy/dx = \\{x \\gt \\tau\\}$ - $x$ gets gradients for those normalised elements that are larger \n",
    "    - $dy/d\\tau = \\{x \\leq \\tau\\}$ - $\\tau$ gets gradients from those normalised elements of x that are smaller\n",
    "    \n",
    "- No mean normalization\n",
    "    - May mean that can be arbitrarily away from 0 but that is why we have TLU not ReLU\n",
    "    - Arbitrary unless done for batch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementation details\n",
    "    - SGD\n",
    "    - 8 GPUs \n",
    "    - 300K steps\n",
    "    - norm stats per GPU for BN\n",
    "    - lr = 0.1 x batch_size / 256 with cosine decay\n",
    "    - other details from [8, 9]\n",
    "    - Metrics\n",
    "        - Accuracy using highest scoring class (precision at 1)\n",
    "        - Accuracy using top-5 scoring classes (recall at 5)\n",
    "     - For comparing other norm methods\n",
    "         - 32 images / GPU = 256 batch_size\n",
    "         \n",
    "    - Object detection\n",
    "        - Fine-tuned baseline\n",
    "            - steps = 25000\n",
    "        - Rest from scratch\n",
    "            - steps = 125000\n",
    "            - batch_size in {62, 32, 16}\n",
    "            - lr = {0.01, 0.05, 0.1} * batch_size / 64\n",
    "            - train_steps = 125000 * 64 / batch_size\n",
    "            - momentum = 0.9\n",
    "            - weight_decay = $4 \\times 10^{-4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Results\n",
    "    - To the effect that FRN always does better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
