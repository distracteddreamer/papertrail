{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style-GAN++ â€” Scribblings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers.convolutional import Conv\n",
    "from tensorflow.python import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revised style block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleBlock(tf.keras.models.Model):\n",
    "    def __init__(self, conv_kwargs, dense_kwargs):\n",
    "        self.conv = tf.keras.layers.Conv2D(**conv_kwargs)\n",
    "        self.bias = self.add_weight(shape=(conv_kwargs['filters'],),\n",
    "                             initializer='zeros',\n",
    "                             trainable=True)\n",
    "        self.dense_mod = tf.keras.layers.Dense(**dense_kwargs)\n",
    "        \n",
    "    def __call__(self, x, style, noise):\n",
    "        y = self.dense_mod(style)\n",
    "        x = self.conv(x) * y\n",
    "        x = x / tf.math.reduce_std(x, axis=[1, 2])\n",
    "        x = tf.nn.bias_add(x, self.bias)\n",
    "        x = x + noise\n",
    "        # TODO: confirm these are the axis\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let there be $C$ filters in the input and $F$ filters in the output. Let the kernel for the $f$-th filter $w_f$ have shape $H \\times W$ and let $p$ be a $C \\times H \\times W$ size patch of the input. The pixel in the $f$-th channel of the output $a_{fi'j'}$ resulting from this input patch convolved with the $f$-th kernel is given as \n",
    "\n",
    "$$a_{fi'j'} = \\sum_{c=0}^{C-1}\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}w_{fcij}p_{cij}$$\n",
    "    \n",
    "In the modulation step we scale the output feature maps of the conv layer by a $F$-dimensional style vector $y$. But we could equivalently achieve this result by scaling the conv kernel so that instead of $a'_{fi'j'} = y_fa_{fi'j'}$ we have \n",
    "\n",
    "$$\n",
    "w'_f = y_fw_f \\\\\n",
    "a'_{fi'j'} = \\sum_{c=0}^{C-1}\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}w'_{fcij}p_{cij} \\\\\n",
    "$$\n",
    "\n",
    "If $p_{cij} \\sim \\mathcal{N}(\\mu, 1)$ (i.i.d with std of 1), then std of the $f$-channel activations is\n",
    "\n",
    "$$\\text{Var}(a_f) = \\text{Var}\\left(\\sum_{cij}w_{fcij}p_{cij}\\right)\n",
    "= \\sum_{cij}\\text{Var}(w_{fcij}p_{cij})\n",
    "= \\sum_{cij}w_{fcij}^2\\text{Var}(p_{cij})\n",
    "= \\sum_{cij}w_{fcij}^2\n",
    "\\\\\\sigma_f = \\sqrt{\\text{Var}(a_f)} = \\sqrt{\\sum_{cij}w_{fcij}^2}$$\n",
    "\n",
    "Since in the norm step the feature maps are scaled by their std, if $p_{cij} \\sim \\mathcal{N}(\\mu, 1)$, then the outputs are scaled by the $L_2$ norm of the weights.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly the variance scaling can be incorporated into the kernel\n",
    "\n",
    "$$\n",
    "w''_f = w'_f / ||w'_f||_2\\\\\n",
    "a''_{fi'j'} = \\sum_{c=0}^{C-1}\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}w''_{fcij}p_{cij} \\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleConv(Conv):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.eps = kwargs.pop('eps')\n",
    "        super(StyleConv, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def _mod_demod_kernel(self, style, noise):\n",
    "        kernel =  self.kernel * style\n",
    "        l2_norm = tf.norm(tf.reshape(kernel, [-1, tf.shape(kernel)[-1]]),\n",
    "                          axis=0, ord=2, keepdims=True)\n",
    "        kernel = kernel / (l2_norm + self.eps)\n",
    "        return kernel\n",
    "    \n",
    "    def call(self, x, style, noise):\n",
    "        outputs = self._convolution_op(x, self._mod_demod_kernel(style))\n",
    "        outputs = outputs + noise\n",
    "        if self.use_bias:\n",
    "            if self.data_format == 'channels_first':\n",
    "                if self.rank == 1:\n",
    "                    # nn.bias_add does not accept a 1D input tensor.\n",
    "                    bias = array_ops.reshape(self.bias, (1, self.filters, 1))\n",
    "                    outputs += bias\n",
    "                else:\n",
    "                    outputs = nn.bias_add(outputs, self.bias, data_format='NCHW')\n",
    "            else:\n",
    "                outputs = nn.bias_add(outputs, self.bias, data_format='NHWC')\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "class StyleConv2D(StyleConv):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs['rank'] = 2\n",
    "        super(StyleConv2D, self).__init__(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy regularisation\n",
    "- In the interests of (speed ?) reg terms are executed only after every $k$ training iterations\n",
    "- For $k$ iterations usual loss is used\n",
    "- Then for 1 iteration reg loss is used\n",
    "- Adam is shared with its parameters adjusted since for every $k$ iterations there are now $k + 1$ iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adam_lazy_reg(beta1, beta2, lam, n_iters):\n",
    "    factor = n_iters / (n_iters + 1)\n",
    "    return tf.optimizers.Adam(beta1=beta1**factor, \n",
    "                              beta2=beta2**factor, \n",
    "                              lam=factor*lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path length regularisation\n",
    "\n",
    "I think that since $\\mathbf{y}$ are referred to as random images, we have that $\\nabla_\\mathbf{w}(g(\\mathbf{w})\\cdot \\mathbf{y}) = \\mathbf{J}_\\mathbf{w}^T\\mathbf{y} + g(\\mathbf{w})\\nabla_\\mathbf{w}\\mathbf{y} = \\mathbf{J}_\\mathbf{w}^T\\mathbf{y}$ because if $\\mathbf{y}$ is some random image from $\\mathcal{N}(0,\\mathbf{I})$ its gradients with respect to $\\mathbf{w}$ are 0. \n",
    "\n",
    "This contrivance used as it gives us $\\mathbf{J}_\\mathbf{w}^T\\mathbf{y}$ without having to find the Jacobian. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected value of  $\\lVert \\mathbf{J}_\\mathbf{w}^T\\mathbf{y} \\rVert_2^2$:\n",
    "\n",
    "\n",
    "$$E_{\\mathbf{y}}\\left[\\left\\lVert\\mathbf{J}_\\mathbf{w}^T\\mathbf{y}\\right\\rVert_2^2\\right]\n",
    "= E_{\\mathbf{y}}\\left[\\sum_a\\left(\\sum_b{\\mathbf{J}_{\\mathbf{w},ab}}\\mathbf{y}_b\\right)^2\\right]\n",
    "= E_{\\mathbf{y}}\\left[\\sum_a\\left(\\sum_b\\sum_{b'}{\\mathbf{J}_{\\mathbf{w},ab}}\\mathbf{y}_b\n",
    "{\\mathbf{J}_{\\mathbf{w},ab'}}\\mathbf{y}_{b'}\\right)\\right]\n",
    "\\\\ = \\sum_a\\sum_b {\\mathbf{J}_{\\mathbf{w},ab}}^2 E_{\\mathbf{y_b}}\\left[\\mathbf{y}_b^2\\right]\n",
    "+\n",
    "\\sum_a\\sum_{b, b\\neq b'}\\sum_{b'}{\\mathbf{J}_{\\mathbf{w},ab}}\n",
    "{\\mathbf{J}_{\\mathbf{w},ab'}}E_{\\mathbf{y_b}}\\left[\\mathbf{y}_{b}\\right]E_{\\mathbf{y_{b'}}}\\left[\\mathbf{y}_{b'}\\right]\n",
    "\\\\ = \\sum_a\\sum_b {\\mathbf{J}_{\\mathbf{w},ab}}^2 = \\text{tr}\\left({\\mathbf{J}_{\\mathbf{w}}}{\\mathbf{J}_{\\mathbf{w}}}^T\\right)\n",
    "$$ \n",
    "\n",
    "Since the elements of $\\mathbf{y}$ are independent the expectation of each element can be found separately. We also rely on the following:\n",
    "    \n",
    "$$E[\\mathbf{y_b}] = 0 \\implies E[\\mathbf{y_b}^2] = \\text{Var}(\\mathbf{y_b}) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimising the above makes the elements of the Jacobian small. In practice a value $a$ is subtracted. \n",
    "\n",
    "$$E_{\\mathbf{y}}\\left[\\left(\\left\\lVert\\mathbf{J}_\\mathbf{w}^T\\mathbf{y}\\right\\rVert_2 - a\\right)^2\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value $a$ is made to be the exponential moving average of $\\left\\lVert\\mathbf{J}_\\mathbf{w}^T\\mathbf{y}\\right\\rVert_2$. Let us think about how this regularisation might work:\n",
    "\n",
    "- At any step $J_w$ depends on the weights at that point.\n",
    "- Say that at step $t$ $\\left\\lVert\\mathbf{J}_\\mathbf{w}^T\\mathbf{y}\\right\\rVert_2^2$ is quite different from $a$ which pushes up the loss --- simplistically this encourages the weights to to push $\\left\\lVert\\mathbf{J}_\\mathbf{w}^T\\mathbf{y}\\right\\rVert_2^2$ towards $a$.\n",
    "- The weights will also be influenced by the other losses.\n",
    "- At the next step $a$ has been pushed up a bit so if $\\left\\lVert\\mathbf{J}_\\mathbf{w}^T\\mathbf{y}\\right\\rVert_2^2$ has decreased too much, then in the step after it will be pushed up again\n",
    "- Possibly the term will become more stable, staying near to some value of $a$ as the network as a whole becomes more stable. \n",
    "- What this value is depends on the weights that work well for the task as a whole. \n",
    "- However the effect of the regularisation is to exert some control on the Jacobian. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "- Dimensionality of $Z$ and $W$: 512\n",
    "- Mapping network architecture \n",
    "    - 8 fully connected layers\n",
    "    - 100$\\times$ lower lr\n",
    "- Architecture\n",
    "    - leaky ReLU, $\\alpha=0.2$\n",
    "    - bilinear filtering in all up/downsampling layers (?)\n",
    "    - minibatch std layer at end of discriminator\n",
    "- Training\n",
    "    - equalized lr for all trainable params (?)\n",
    "    - EMA of generator weights\n",
    "    - style mixing reg\n",
    "    - non-saturating logistic loss with $R_1$ reg\n",
    "    - Adam optimiser ($\\beta_1 = 0, \\beta_2 = 0.99, \\epsilon = 10^{-8}$)\n",
    "    - batch_size 32\n",
    "    - 8 GPUs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
