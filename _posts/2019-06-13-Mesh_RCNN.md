---
layout: post
title:  "Mesh RCNN"
date:   2019-07-12 11:51:32 +0100
categories: jekyll update
---
These are my notes on the paper [Mesh R-CNN](https://arxiv.org/pdf/1906.02739). All mistakes are my own. 

Introduction
- An extension to Mask-RCNN that generates a 3D mesh for each object segmented by Mask-RCNN.

Architecture
- Voxel branch
    - Parallel to the box and mask branches of Mask-RCNN with independent weights but sharing the same backbone.
    - Output is a coarse voxel probability map represented by pixel maps of resolution $H x W$ with $N$ channels where for each position $(x,y)$ on the grid the i-th channel indicates the probability that $z = i$.
- Cubification
    - Output is transformed to a coarse cubic mesh in an efficient manner 
    - This step does not seek to change the geometry of the predicted shape but only its representation from a voxel grid into a mesh
- Mesh refinement
    - A sequence of blocks, where the first one refines the initial mesh and where each subsequent block refines the intermediate mesh output by the previous block. 
    - VertAlign
        - Initially 3D output is in an isometric grid so spacing between the x and y coordinates at all distances $z$
        - However objects become smaller as they recede from the camera in order to maintain pixelwise correspondence between the image and predictions they are projected using the camera's known intrinsic matrix $K$ into the world space.
        - Like in RoIAlign bilinear interpolation is used to estimate the exact feature vectors for the projected points. 
        - The result is a set of vertex and edges plus a feature vector for each vertex
        - This step is applied to the intermediate grids of subsequent layers but I am not sure how to interpret it for subsequent steps since the points have already been projected.
        - In the second and subsequent blocks the input feature vectors are concatenated with the feature vectors 
    - Graph Convolution 
        - Updates the feature vectors for each vertex  $i$ using a sequence of graph convolutions $f^\prime_i = \text{ReLU}\left(W_0f_i + \sum_{j \in \mathcal{N}(i)}W_1f_j\right)$ where $\mathcal{N}(i)$ is set of vertices to which vertex $i$ is connected. 
    - Vertex refinement
        - Vertex positions are updated as $v_i' = v_i + \tanh\left(W_{vert}[f_i;v_i]\right)$
        - This changes the geometry but not the topology of the mesh.
        - If you think the mesh as a graph and disregard the coordinates the vertices represent, the connectivity between the vertices does not change but the values of the vertices does.
        - In this step the feature vectors associated with each vertex are unchanged.
        - The unchanged topology at the end of the mesh refinement block allows us to concatenate the feature vectors from previous blocks in the VertAlign step.

Loss functions
- Since it is challenging to define losses for a mesh representation, points are densely sampled from the mesh in order to calculate the losses.
- The Chamfer distance measures the similarity of the predicted and ground truth point clouds
    $$L_\text{cham}(P, Q) = |P^-1|\sum_{(p, q) \in \Lambda P,Q}\lVert p - q\rVert^2 + |Q^-1|\sum_{(q, p) \in \Lambda Q,P}\lVert a - b\rVert^2$$
- The (absolute) normal distance measures the similarity of the face orientation of the predicted and ground truth meshes 
    $$L_\text{norm}(P, Q) = - |P^-1|\sum_{(p, q) \in \Lambda P,Q}\lvert u_p \dot u_q \rvert^2 - |Q^-1|\sum_{(q, p) \in \Lambda Q,P}\lvert  u_q \dot u_p \rvert^2$$
- Minimising these losses does not necessarily produce a good quality mesh so a shape regularizer is added in the form of an edge loss which encourages the edges of faces to be small resulting in a smoother mesh
    $$L_\text{edge}(V, E) = \frac{1}{|E|}\sum_{(v, v')\in E}\lVert v - v' \rVert^2$$

Evaluation
- The following metrics are used:
    - $L_{\text{cham}}$
    - Normal consistency which is 1 - $L_{\text{norm}}$
    - $F_1^{\tau}$ score, which is the $F_1$ score where the distance $\tau$ is used to define the precision and recall:
        - Precision is the fraction of gt points within $\tau$ of a pred point
        - Recall is the fraction of gt points within $\tau$ of a pred point

Experiments
- ShapeNet
    - Data
        - Textured CAD models
        - These are rendered into RGB images from 24 random viewpoints 
     - Performance
        - Model is on par with Pixel2Mesh+ (an earlier model Pixel2Mesh with some additions) on the full dataset but when evaluted on just objects with holes does better (since it starts off with a sphere that needs to be transformed to the object)
        - Model also outperforms whilst producing fewer faces 
- Pix3D
    - Data
        - 10069 real-world images and 395 unique 3D models (there can be several images per model where the object has varying appearances)
        - They make two splits, a random split and a disjoint one in which models appearing in validation do not appear in train
    - Performance
        - On both splits on all but one object category MeshRCNN outperforms other models
        - In general performance is lower compared to ShapeNet because this is a more difficult dataset. 

    
    