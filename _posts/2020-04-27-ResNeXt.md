---
layout: post
title:  "[WIP] ResNeXt"
date:   2020-04-27 13:42:12
categories: jekyll update
---


These are my notes on the paper [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431). All mistakes are my own.

## ResNeXt building block

The key idea is that the $F$ channels of the input are split into $C$ parts which are then processed independently before they are finally added together. In the na√Øve version multiple parallel layers are used

![png]({{ site.baseurl }}/assets/ResNeXt/resnext_simple.jpg)

However as shown below these can be implemented more efficiently by merging the `conv1x1` layers and using group convolutions (which will have efficient GPU implementations in some frameworks) for the `conv3x3` layer.

![png]({{ site.baseurl }}/assets/ResNeXt/resnext_efficient.jpg)
